{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mineração de Emoção em Textos com Python e NLTK<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será utilizada uma base de dados com 20 frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia está muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de stopwords utilizada será a existente do NLTK. Stopwords são palavras que não são relevantes para a análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima função remove as stopwords das frases da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removestopwords(texto):\n",
    "    frases=[]\n",
    "    for (palavras, emocao) in texto:\n",
    "        semstop = [p for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frases.append((semstop, emocao))\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, é removido o radical das palavras, processo chamado de stemming, e armazenado na variável frasescomstemming. Esse processo tem a finalidade de reduzir o tamanho das palavras para armazenamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicastemmer(texto):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frasesstemming = []\n",
    "    for [palavras, emocao] in texto:\n",
    "        comstemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frasesstemming.append((comstemming, emocao))\n",
    "    return frasesstemming\n",
    "\n",
    "frasescomstemming = aplicastemmer(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para listar todas as palavras da base, usamos essa função, sem as stopwords e com stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admir', 'muit', 'sint', 'complet', 'am', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'nov', 'dia', 'bonit', 'cont', 'result', 'test', 'fiz', 'dia', 'ont', 'am', 'lind', 'amizad', 'am', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'dia', 'deix', 'apavor', 'lug', 'apavor', 'perd', 'outr', 'jog', 'elimin', 'deix', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med', 'med', 'med', 'result', 'test']\n"
     ]
    }
   ],
   "source": [
    "def buscapalavras(frases):\n",
    "\ttodaspalavras = []\n",
    "\tfor (palavras, emocao) in frases:\n",
    "\t\ttodaspalavras.extend(palavras)\n",
    "\treturn todaspalavras\n",
    "\n",
    "palavras = buscapalavras(frasescomstemming)\n",
    "print(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extração das palavras unicas existentes na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('am', 4), ('dia', 4), ('med', 3), ('nov', 2), ('result', 2), ('test', 2), ('deix', 2), ('apavor', 2), ('admir', 1), ('muit', 1), ('sint', 1), ('complet', 1), ('maravilh', 1), ('sent', 1), ('anim', 1), ('bem', 1), ('hoj', 1), ('bel', 1), ('dirig', 1), ('carr', 1), ('bonit', 1), ('cont', 1), ('fiz', 1), ('ont', 1), ('lind', 1), ('amizad', 1), ('vai', 1), ('dur', 1), ('sempr', 1), ('amedront', 1), ('ameac', 1), ('lug', 1), ('perd', 1), ('outr', 1), ('jog', 1), ('elimin', 1), ('pav', 1), ('tom', 1), ('cuid', 1), ('lobisom', 1), ('descobr', 1), ('encrenc', 1), ('trem', 1)]\n",
      "dict_keys(['admir', 'muit', 'sint', 'complet', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'bonit', 'cont', 'result', 'test', 'fiz', 'ont', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'deix', 'apavor', 'lug', 'perd', 'outr', 'jog', 'elimin', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med'])\n"
     ]
    }
   ],
   "source": [
    "def buscafrequencia(palavras):\n",
    "\tpalavras = nltk.FreqDist(palavras)\n",
    "\treturn palavras\n",
    "\n",
    "frequencia = buscafrequencia(palavras)\n",
    "print(frequencia.most_common(50))\n",
    "\n",
    "def buscapalavrasunicas(frequencia):\n",
    "\tfreq = frequencia.keys()\n",
    "\treturn freq\n",
    "\t\n",
    "palavrasunicas = buscapalavrasunicas(frequencia)\n",
    "print(palavrasunicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extração das palavras de cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admir': False, 'muit': False, 'sint': False, 'complet': False, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': True, 'bem': False, 'hoj': False, 'bel': False, 'dia': True, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}\n"
     ]
    }
   ],
   "source": [
    "def extratorpalavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavrasunicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "caracteristicasfrase = extratorpalavras(['am', 'nov', 'dia'])\n",
    "print(caracteristicasfrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extração das palavras de todas as frases (Usada na tabela de probabilidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ({'admir': False, 'muit': False, 'sint': True, 'complet': True, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ...]\n"
     ]
    }
   ],
   "source": [
    "basecompleta = nltk.classify.apply_features(extratorpalavras, frasescomstemming)\n",
    "print(basecompleta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construção da tabela de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exibe os resultados possíveis: \n",
      "['alegria', 'medo']\n",
      "Exibe as estatísticas sobre os dados da base. Ex: Quando dia = true, as chances de a frase ser categorizada como alegria é maior que medo.\n",
      "Most Informative Features\n",
      "                     dia = True           alegri : medo   =      2.3 : 1.0\n",
      "                      am = False            medo : alegri =      1.6 : 1.0\n",
      "                     med = False          alegri : medo   =      1.4 : 1.0\n",
      "                     dia = False            medo : alegri =      1.3 : 1.0\n",
      "                  apavor = False          alegri : medo   =      1.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(basecompleta)\n",
    "print(\"Exibe os resultados possíveis: \")\n",
    "print(classificador.labels())\n",
    "print(\"Exibe as estatísticas sobre os dados da base. Ex: Quando dia = true, as chances de a frase ser categorizada como alegria é maior que medo.\")\n",
    "print(classificador.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificando uma frase teste. Ao aplicar no classificador, já realiza a remoção das stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase teste: estou com medo\n",
      "Stemming: ['est', 'com', 'med']\n",
      "Sentimento: medo\n",
      "alegria: 4.104610%\n",
      "medo: 95.895390%\n"
     ]
    }
   ],
   "source": [
    "teste = 'estou com medo'\n",
    "print(\"Frase teste: %s\" % teste)\n",
    "testestemming = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavras) in teste.split():\n",
    "\tcomstem = [p for p in palavras.split()]\n",
    "\ttestestemming.append(str(stemmer.stem(comstem[0])))\n",
    "print(\"Stemming: %s\" %testestemming)\n",
    "\n",
    "novo = extratorpalavras(testestemming)\n",
    "#print(novo)\n",
    "\n",
    "print(\"Sentimento: %s\" % classificador.classify(novo))\n",
    "distribuicao = classificador.prob_classify(novo)\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f%%\" % (classe, distribuicao.prob(classe)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
